{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "finish reading lines\n",
      "proc data 0\n",
      "proc data 1000\n",
      "proc data 2000\n",
      "proc data 3000\n",
      "proc data 4000\n",
      "proc data 5000\n",
      "proc data 6000\n",
      "proc data 7000\n",
      "proc data 8000\n",
      "proc data 9000\n",
      "proc data 10000\n",
      "mean text length: 196.016749311\n",
      "mean hyp length: 92.3061983471\n",
      "max text length: 1704\n",
      "max hyp length: 280\n",
      "min text length: 5\n",
      "min hyp length: 22\n",
      "mean text length: 35.1777961433\n",
      "mean hyp length: 16.497107438\n",
      "max text length: 303\n",
      "max hyp length: 46\n",
      "min text length: 2\n",
      "min hyp length: 4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "mode='dev'\n",
    "n_ans='same'\n",
    "n_sent=0\n",
    "span_mode='f1'  # exact or overlap or f1\n",
    "num_class=2\n",
    "predict=False\n",
    "verbose=False\n",
    "# input_data=open(r'D:\\users\\t-yicxu\\data\\squad\\\\'+mode+'-v1.1.json',encoding='utf-8')\n",
    "input_data=open(r'D:\\users\\t-yicxu\\data\\squad\\\\'+mode+'\\\\'+mode+'-stanford.json',encoding='utf-8')\n",
    "if mode=='dev':\n",
    "\tdump_data=open(r'D:\\users\\t-yicxu\\biglearn\\res_v16_dev.score.0.dump',encoding='utf-8')\n",
    "else:\n",
    "\tdump_data=open(r'D:\\users\\t-yicxu\\biglearn\\res_v16_train.score.0.dump',encoding='utf-8')\n",
    "output_file=open(r'D:\\users\\t-yicxu\\data\\squad\\entail_'+mode+'_%s_%d_%s_%dclass.tsv' %(str(n_ans),n_sent,span_mode,num_class),'w',encoding='utf-8')\n",
    "\n",
    "print('begin')\n",
    "\n",
    "texts=[]\n",
    "hyps=[]\n",
    "labels=[]\n",
    "ids=[]\n",
    "prediction={}\n",
    "\n",
    "# all_data=json.load(input_data)\n",
    "all_data={'data':[]}\n",
    "line=input_data.readline()\n",
    "# print(line)\n",
    "assert line.strip()=='SQuDA'\n",
    "for line in input_data:\n",
    "\tall_data['data'].append(json.loads(line))\n",
    "print('finish reading lines')\n",
    "\n",
    "proc_all_data=[]\n",
    "for (ii,data) in enumerate(all_data['data']):\n",
    "\tif ii % 1000==0:\n",
    "\t\tprint('proc data',ii)\n",
    "\ttry:\n",
    "\t\t# assert len(data['answer_pos'])==1\n",
    "\t\tassert len(data['answer_pos'][0])==2\n",
    "\t\tassert len(data['answer_pos'][0][0])==2\n",
    "\texcept AssertionError:\n",
    "\t\tprint(data['answer_pos'])\n",
    "\t\tinput('check')\n",
    "\tanswer_datas=data['answer_pos']\n",
    "\tans_data_collection=set()\n",
    "\tfor a_data in answer_datas:\n",
    "\t\tans_data_collection.add(((a_data[0][0],a_data[0][1]),(a_data[1][0],a_data[1][1])))\n",
    "\tnew_answers=[]\n",
    "\tfor tup in ans_data_collection:\n",
    "\t\tnew_answers.append([[tup[0][0],tup[0][1]],[tup[1][0],tup[1][1]]])\n",
    "\tif verbose:\n",
    "\t\tprint('new_answers=',new_answers)\n",
    "\tdump_line=next(dump_data)\n",
    "\tfor ans_span in new_answers:\n",
    "\n",
    "\t\tgt_sent=range(ans_span[0][0],ans_span[1][0]+1)\n",
    "\t\tgt_sent_texts=[' '.join([t for t in data['context_tokens'][k]]) for k in gt_sent]\n",
    "\t\tgt_text=' '.join(gt_sent_texts)\n",
    "\t\tques_text=' '.join(data['question_tokens'])\n",
    "\t\tn_context_token=sum([len(sent) for sent in data['context_tokens']])\n",
    "\n",
    "\n",
    "\t\t# Insert ground truth\n",
    "\t\tgt_ans_words=[]\n",
    "\t\tfor sentid in gt_sent:\n",
    "\t\t\tst_pos=ans_span[0][1] if sentid==ans_span[0][0] else 0\n",
    "\t\t\tend_pos=ans_span[1][1] if sentid==ans_span[1][0] else len(data['context_tokens'][sentid])-1\n",
    "\t\t\t# print(st_pos,end_pos)\n",
    "\t\t\tfor idx in range(st_pos,end_pos+1):\n",
    "\t\t\t\tgt_ans_words.append(data['context_tokens'][sentid][idx])\n",
    "\t\tgt_ans=' '.join(gt_ans_words)\n",
    "\t\tlabels.append(1)\n",
    "\t\ttexts.append(gt_text)\n",
    "\t\tthishyp=' '.join([ques_text,gt_ans])\n",
    "\t\thyps.append(thishyp)\n",
    "\t\tids.append(data['id']+'_gt')\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('label=%d, text=%s, hyp=%s' % (labels[-1],texts[-1],hyps[-1]))\n",
    "\t\t\tinput('check')\n",
    "\n",
    "\t\t#insert wrong texts\n",
    "\t\tavailable_sents=set(range(len(data['context_tokens'])))-set(gt_sent)\n",
    "\t\tchoose_num=min(n_sent,len(available_sents))\n",
    "\t\tif choose_num==0:\n",
    "\t\t\tcontinue\n",
    "\t\tchosen_sents=np.random.choice(list(available_sents),choose_num)\n",
    "\t\tfor sentid in chosen_sents:\n",
    "\t\t\ttexts.append(' '.join(data['context_tokens'][sentid]))\n",
    "\t\t\thyps.append(' '.join([ques_text,gt_ans]))\n",
    "\t\t\tif num_class==2:\n",
    "\t\t\t\tlabels.append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels.append(3)\n",
    "\t\t\tids.append(data['id']+'_sent')\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint('label=%d, text=%s, hyp=%s' % (labels[-1],texts[-1],hyps[-1]))\n",
    "\t\t\t\tinput('check')\t\t\t\n",
    "\n",
    "\t#insert potential wrong answers\n",
    "\tspan_probs=[]\n",
    "\tspans=[]\n",
    "\t\n",
    "\ttoken_probs=dump_line.split(' ')\n",
    "\n",
    "\t# if i>=len(proc_passages):\n",
    "\t# \tbreak\n",
    "\tif len(token_probs)!=n_context_token:\n",
    "\t\tprint('question',ii)\n",
    "\t\tprint('prediction length=', len(token_probs))\n",
    "\t\tprint('tokenize length=',n_context_token)\n",
    "\t\tprint(data)\n",
    "\t\tprint(dump_line)\n",
    "\t\tinput('check')\n",
    "\t\tcontinue\n",
    "\tstartps=[]\n",
    "\tendps=[]\n",
    "\tfor (tid,tp) in enumerate(token_probs):\n",
    "\t\tpid,startp,endp=tp.split('#')\n",
    "\t\tassert tid==int(pid)\n",
    "\t\tstartps.append(float(startp))\n",
    "\t\tendps.append(float(endp))\n",
    "\t# print(startps)\n",
    "\t# print(endps)\n",
    "\t# input('check')\n",
    "\tfor id1 in range(n_context_token):\n",
    "\t\tfor id2 in range(id1,min(n_context_token,id1+15)):\n",
    "\t\t\tspan_probs.append(-startps[id1]*endps[id2])\n",
    "\t\t\tspans.append((id1,id2))\n",
    "\tspan_rank=np.argsort(span_probs)\n",
    "\tpartsum=[0]\n",
    "\tall_tokens=sum(data['context_tokens'],[])\n",
    "\tfor sid in range(len(data['context_tokens'])):\n",
    "\t\tpartsum.append(partsum[-1]+len(data['context_tokens'][sid]))\n",
    "\n",
    "\tadded_count=0\n",
    "\tif n_ans=='same':\n",
    "\t\ttarget_num=len(new_answers)\n",
    "\telse:\n",
    "\t\ttarget_num=n_ans\n",
    "\tfirst_ten_perm=np.random.permutation(10)\n",
    "\tfor tmpi in range(len(spans)):\n",
    "\t\tif tmpi<10:\n",
    "\t\t\ti=first_ten_perm[tmpi]\n",
    "\t\telse:\n",
    "\t\t\ti=tmpi\n",
    "\t\tthis_start=spans[span_rank[i]][0]\n",
    "\t\tthis_end=spans[span_rank[i]][1]\n",
    "\n",
    "\t\tthis_ans=' '.join([all_tokens[idx] for idx in range(this_start,this_end+1)])\n",
    "\t\tif i==0:\n",
    "\t\t\tprediction[data['id']]=this_ans\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('this_start=',this_start,'this_end=',this_end)\n",
    "\t\t\t# print('gt_start=',gt_span_start,'gt_end=',gt_span_end)\n",
    "\n",
    "\t\tcanuse=True\n",
    "\t\tfor a_gt_span in new_answers:\n",
    "\t\t\ta_gt_span_start=partsum[a_gt_span[0][0]]+a_gt_span[0][1]\n",
    "\t\t\ta_gt_span_end=partsum[a_gt_span[1][0]]+a_gt_span[1][1]\n",
    "\t\t\tif span_mode=='exact':\n",
    "\t\t\t\tif this_start==a_gt_span_start and this_end==a_gt_span_end:\n",
    "\t\t\t\t\tcanuse=False\n",
    "\t\t\telif span_mode=='f1':\n",
    "\t\t\t\toverlap_length=max(min(a_gt_span_end,this_end)+1-max(a_gt_span_start,this_start),0)\n",
    "\t\t\t\tif overlap_length==0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprecision=overlap_length/(this_end-this_start+1)\n",
    "\t\t\t\t\trecall=overlap_length/(a_gt_span_end - a_gt_span_start+1)\n",
    "\t\t\t\t\tf1=2*precision*recall/(precision+recall)\n",
    "\t\t\t\t\tif f1>=0.5:\n",
    "\t\t\t\t\t\tcanuse=False\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tassert span_mode=='overlap'\n",
    "\t\t\t\tif (this_start - a_gt_span_end)*(this_end - a_gt_span_start)<=0:\n",
    "\t\t\t\t\tcanuse=False\n",
    "\n",
    "\n",
    "\t\tif not canuse:\n",
    "\t\t\tcontinue\n",
    "\t\tfor start_sent in range(len(partsum)):\n",
    "\t\t\tif partsum[start_sent+1]>=this_start:\n",
    "\t\t\t\tbreak\n",
    "\t\tfor end_sent in range(len(partsum)):\n",
    "\t\t\tif partsum[end_sent]>this_end:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\ttext_sent=range(start_sent,end_sent)\n",
    "\t\tthis_text=' '.join([' '.join([t for t in data['context_tokens'][k]]) for k in text_sent])\n",
    "\t\tassert len(this_text)!=0\n",
    "\n",
    "\t\ttexts.append(this_text)\n",
    "\t\tthis_ans=' '.join([all_tokens[idx] for idx in range(this_start,this_end+1)])\n",
    "\t\tthishyp=' '.join([ques_text,this_ans])\n",
    "\t\thyps.append(thishyp)\n",
    "\t\tif num_class==2:\n",
    "\t\t\tlabels.append(0)\n",
    "\t\telse:\n",
    "\t\t\tlabels.append(2)\n",
    "\t\tids.append(data['id']+'_ans_%d' % (tmpi))\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('label=%d, text=%s, hyp=%s, id=%s' % (labels[-1],texts[-1],hyps[-1],ids[-1]))\n",
    "\t\t\tinput('check')\n",
    "\t\tadded_count+=1\n",
    "\t\tif added_count==target_num:\n",
    "\t\t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "\t\t# print('inside here')\n",
    "\t\t# break\n",
    "if predict:\n",
    "\tpredict_out=open(r'D:\\users\\t-yicxu\\BiMPM_1.0\\model_data\\sample_predict_tmp.json','w',encoding='utf-8')\n",
    "\tjson.dump(prediction,predict_out,ensure_ascii=False)\n",
    "for i in range(len(hyps)):\n",
    "\tprint('%d\\t%s\\t%s\\t%s' % (labels[i], texts[i],hyps[i],ids[i]),file=output_file)\t\n",
    "text_lens=[len(a) for a in texts]\n",
    "hyp_lens=[len(a) for a in hyps]\n",
    "\n",
    "n_words_text=[]\n",
    "n_words_hyp=[]\n",
    "for i in range(len(hyps)):\n",
    "\tn_words=len(hyps[i].split(' '))\n",
    "\tn_words_hyp.append(n_words)\n",
    "\n",
    "\tn_words=len(texts[i].split(' '))\n",
    "\tn_words_text.append(n_words)\n",
    "\n",
    "\n",
    "print('mean text length:',np.mean(text_lens))\n",
    "print('mean hyp length:',np.mean(hyp_lens))\n",
    "\n",
    "print('max text length:',np.max(text_lens))\n",
    "print('max hyp length:',np.max(hyp_lens))\n",
    "\n",
    "print('min text length:',np.min(text_lens))\n",
    "print('min hyp length:',np.min(hyp_lens))\n",
    "\n",
    "\n",
    "print('mean text length:',np.mean(n_words_text))\n",
    "print('mean hyp length:',np.mean(n_words_hyp))\n",
    "\n",
    "print('max text length:',np.max(n_words_text))\n",
    "print('max hyp length:',np.max(n_words_hyp))\n",
    "print('min text length:',np.min(n_words_text))\n",
    "print('min hyp length:',np.min(n_words_hyp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_words_text=[]\n",
    "n_words_hyp=[]\n",
    "for i in range(len(hyps)):\n",
    "\tn_words=len(hyps[i].split(' '))\n",
    "\tn_words_hyp.append(n_words)\n",
    "\n",
    "\tn_words=len(texts[i].split(' '))\n",
    "\tn_words_text.append(n_words)\n",
    "\n",
    "\n",
    "print('mean text length:',np.mean(text_lens))\n",
    "print('mean hyp length:',np.mean(hyp_lens))\n",
    "\n",
    "print('max text length:',np.max(text_lens))\n",
    "print('max hyp length:',np.max(hyp_lens))\n",
    "\n",
    "print('mean text length:',np.mean(n_words_text))\n",
    "print('mean hyp length:',np.mean(n_words_hyp))\n",
    "\n",
    "print('max text length:',np.max(n_words_text))\n",
    "print('max hyp length:',np.max(n_words_hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , 42 ( 1825 ) . In what year was Wayman v. Southard tried by the U.S. Supreme Court ? 1825 56de2c7fcffd8e1900b4b617_gt\n",
      "[ N 18 ] How many court trials did Meucci participate in ? 18 56df9dbd4a1a83140091eb99_ans_0\n",
      "( 1986 ) . when was mr. fingers ' \" can you feel it ? \" released ? 1986 57069c2652bb891400689add_gt\n",
      "Snowfall is rare . What type of weather is a rarity in Houston ? Snowfall 570a86fe6d058f1900182f4a_gt\n",
      "Compute ! Who reported that Nintendo sold 7 million NES systems ? Compute ! 57111d93a58dae1900cd6c65_gt\n",
      "U.S. ( 20 % ) ; 2 . Which country had the lowest rate of software piracy ? U.S. 5726dcc0f1498d1400e8eda9_gt\n",
      "[ Lk . 23:28 -31 ] Where are the words found in the Gospel ? Lk . 23:28 -31 572781c65951b619008f8b8b_gt\n",
      "[ n 2 ] How many previously-separate phyla did the 2007 study reclassify ? 2 572835282ca10214002da0c6_ans_0\n",
      "She died in 1945 . In which year did his wife die ? 1945 572e904bdfa6aa1500f8d149_gt\n",
      "Two bloody noses . How many bloody noses did Spielberg get in High School ? Two 572e847d03f9891900756716_gt\n",
      "Two bloody noses . How many bloody noses did Spielberg get in high school ? Two 57318ba805b4da19006bd28c_gt\n",
      "He died in 78 BC . In what year did Sulla die ? 78 BC 57301781b2c2fd1400568852_gt\n",
      "He died in 78 BC . In what year did Sulla succesfully take over the populares controlled city ? 78 BC 57301781b2c2fd1400568850_ans_3\n",
      "She fled to Xi'an . Where did Cixi go after Beijing fell to the 8 armies ? Xi'an 57314deaa5e9cc1400cdbe43_gt\n"
     ]
    }
   ],
   "source": [
    "for (i,text) in enumerate(texts):\n",
    "    if len(text)<=20:\n",
    "        print(text,hyps[i],ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_vec_path': 'D:\\\\users\\\\t-yicxu\\\\data\\\\snli_1.0\\\\word2vec_nounk_withdev.txt', 'dev_path': 'D:\\\\users\\\\t-yicxu\\\\data\\\\snli_1.0\\\\dev.tsv', 'word_level_MP_dim': -1, 'aggregation_lstm_dim': 300, 'model_dir': 'D:\\\\users\\\\t-yicxu\\\\model_data\\\\BiMPM\\\\', 'train_path': 'D:\\\\users\\\\t-yicxu\\\\data\\\\snli_1.0\\\\train.tsv', 'wo_maxpool_match': False, 'with_POS': False, 'wo_attentive_match': False, 'optimize_type': 'adam', 'context_layer_num': 2, 'with_highway': True, 'with_lex_decomposition': False, 'test_path': 'D:\\\\users\\\\t-yicxu\\\\data\\\\snli_1.0\\\\test.tsv', 'POS_dim': 20, 'char_lstm_dim': 100, 'batch_size': 60, 'max_char_per_word': 10, 'learning_rate': 0.001, 'lex_decompsition_dim': -1, 'suffix': 'snli_newconfig_3class_rerun', 'with_filter_layer': False, 'wo_full_match': False, 'lambda_l2': 0.0, 'with_aggregation_highway': True, 'wo_char': False, 'context_lstm_dim': 100, 'with_NER': False, 'with_match_highway': True, 'NER_dim': 20, 'fix_word_vec': True, 'max_sent_length': 100, 'highway_layer_num': 1, 'wo_max_attentive_match': False, 'aggregation_layer_num': 2, 'MP_dim': 10, 'wo_left_match': False, 'max_epochs': 10, 'dropout_rate': 0.1, 'char_emb_dim': 20, 'wo_right_match': False}\n",
      "MP_dim=10, NER_dim=20, POS_dim=20, aggregation_layer_num=2, aggregation_lstm_dim=100, base_dir='/u/zhigwang/zhigwang1/sentence_match/snli', batch_size=60, char_emb_dim=20, char_lstm_dim=100, context_layer_num=2, context_lstm_dim=100, dropout_rate=0.1, fix_word_vec=True, highway_layer_num=1, lambda_l2=0.0, learning_rate=0.001, lex_decompsition_dim=-1, max_char_per_word=10, max_epochs=10, max_sent_length=100, optimize_type='adam', suffix='snli_7', with_NER=False, with_POS=False, with_aggregation_highway=True, with_filter_layer=False, with_highway=True, with_lex_decomposition=False, with_match_highway=True, wo_attentive_match=False, wo_char=False, wo_full_match=False, wo_left_match=False, wo_max_attentive_match=False, wo_maxpool_match=False, wo_right_match=False, word_level_MP_dim=-1\n"
     ]
    }
   ],
   "source": [
    "config1=json.load(open('config1.json'))\n",
    "config2=open('config2.json').readline()\n",
    "print(config1)\n",
    "print(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_rate': '0.1', 'word_level_MP_dim': '-1', 'wo_maxpool_match': 'False', 'base_dir': \"'/u/zhigwang/zhigwang1/sentence_match/snli'\", 'wo_left_match': 'False', 'with_POS': 'False', 'wo_attentive_match': 'False', 'optimize_type': \"'adam'\", 'context_layer_num': '2', 'with_highway': 'True', 'with_lex_decomposition': 'False', 'POS_dim': '20', 'aggregation_lstm_dim': '100', 'wo_right_match': 'False', 'batch_size': '60', 'max_char_per_word': '10', 'learning_rate': '0.001', 'lex_decompsition_dim': '-1', 'suffix': \"'snli_7'\", 'with_filter_layer': 'False', 'wo_full_match': 'False', 'lambda_l2': '0.0', 'with_aggregation_highway': 'True', 'wo_char': 'False', 'context_lstm_dim': '100', 'with_NER': 'False', 'with_match_highway': 'True', 'NER_dim': '20', 'fix_word_vec': 'True', 'max_sent_length': '100', 'highway_layer_num': '1', 'wo_max_attentive_match': 'False', 'aggregation_layer_num': '2', 'MP_dim': '10', 'max_epochs': '10', 'char_emb_dim': '20', 'char_lstm_dim': '100'}\n"
     ]
    }
   ],
   "source": [
    "config2_str=config2\n",
    "config2={}\n",
    "cfs=config2_str.split(',')\n",
    "\n",
    "for cf in cfs:\n",
    "    name,val=cf.strip().split('=')\n",
    "    config2[name]=val\n",
    "print(config2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dir '/u/zhigwang/zhigwang1/sentence_match/snli'\n",
      "different: optimize_type config1: adam config2: 'adam'\n",
      "different: aggregation_lstm_dim config1: 300 config2: 100\n",
      "different: suffix config1: snli_newconfig_3class_rerun config2: 'snli_7'\n"
     ]
    }
   ],
   "source": [
    "for name in config2:\n",
    "    if name not in config1:\n",
    "        print(name,config2[name])\n",
    "    else:\n",
    "        if str(config1[name])!=str(config2[name]):\n",
    "            print('different:',name, 'config1:',config1[name],'config2:',config2[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63511486  0.2872599   0.2495    ]\n",
      " [ 0.58446731  0.29140842  0.18010312]] [[ 0.90722052  0.32068919  0.93383881]\n",
      " [ 0.42959248  0.15023892  0.78009962]] [[ 0.4294227   0.49792565  0.539976  ]\n",
      " [ 0.91242794  0.78873997  0.46472936]]\n",
      "[array([[ 1.97175813,  1.10587478,  1.72331476],\n",
      "       [ 1.92648768,  1.23038733,  1.42493212]], dtype=float32)]\n",
      "[[ 1.97175808  1.10587474  1.72331481]\n",
      " [ 1.92648773  1.23038731  1.4249321 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "tf_split=tf.placeholder(tf.float32,[None,None,None])\n",
    "# tf_index=tf.placeholder(tf.int32, [None,None])\n",
    "lengths=tf.placeholder(tf.int32,[None])\n",
    "lengths2=tf.placeholder(tf.int32,[None])\n",
    "mul2=tf.placeholder(tf.float32,[None])\n",
    "mul22=tf.placeholder(tf.float32,[None,None])\n",
    "totallength=lengths+lengths2\n",
    "n_input=tf.shape(lengths)[0]\n",
    "batch_idx=tf.range(n_input)\n",
    "gat_idx=tf.stack([batch_idx,lengths-1],axis=1)\n",
    "# part_res=tf.gather_nd(tf_split,tf_index)\n",
    "part_res=tf.gather_nd(tf_split, gat_idx)\n",
    "mul_input=tf.placeholder(tf.float32,[None,None])\n",
    "mul_part_res=tf.multiply(mul_input,mul2)\n",
    "tf_c=tf_split[:,-1,:]\n",
    "\n",
    "tfadd1=tf.placeholder(tf.float32,[None,None])\n",
    "tfadd2=tf.placeholder(tf.float32,[None,None])\n",
    "tfadd3=tf.placeholder(tf.float32,[None,None])\n",
    "tf_res=tf.add_n([tfadd1,tfadd2,tfadd3])\n",
    "\n",
    "npadd1=np.random.rand(2,3)\n",
    "npadd2=np.random.rand(2,3)\n",
    "npadd3=np.random.rand(2,3)\n",
    "input_dict={tfadd1:npadd1,tfadd2:npadd2,tfadd3:npadd3}\n",
    "\n",
    "# a=np.random.rand(2,3,2)\n",
    "# # b=np.array([[[0,0],[0,2]],[[1,0],[1,2]]])\n",
    "# # b=np.array([[0,1],[1,2]])\n",
    "# # input_dict={tf_split:a,tf_index:b}\n",
    "# c=np.array([1,3])\n",
    "# d=np.array([3,4,5])\n",
    "# dp=np.array([[3],[4]])\n",
    "# ee=np.random.rand(2,3)\n",
    "# print(dp.shape)\n",
    "# # input_dict={tf_split:a, lengths:c,lengths2:d}\n",
    "# input_dict={mul_input:ee,mul2:d}\n",
    "# print(input_dict)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res=sess.run([tf_res],feed_dict=input_dict)\n",
    "    print(npadd1,npadd2,npadd3)\n",
    "    print(res)\n",
    "    print(npadd1+npadd2+npadd3)\n",
    "#     res_c,res,res_tot=sess.run([tf_c, part_res,totallength],feed_dict=input_dict)\n",
    "\n",
    "#     print(a)\n",
    "#     print(res)\n",
    "#     print(res_c)\n",
    "#     print(res_tot)\n",
    "#     print(res_mul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfs-5'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dfs-{}'.format(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "a=json.loads('[1,2,3]')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333531750779\n",
      "[ 0.0833821   0.08337574  0.0833765   0.08339741]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=[-2.48432159, -2.48439789, -2.48438883, -2.48413801]\n",
    "b=[0.33353174,  0.33281344,  0.33365488]\n",
    "print(sum(np.exp(a)))\n",
    "print(np.exp(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "a=pickle.load(open(r'D:\\users\\t-yicxu\\BiMPM_1.0\\model_data\\res.pkg','rb'))\n",
    "return_list=a\n",
    "_,loss_value, pred, prob, all_probs, correct, gate_prob, gate_log_prob, weighted_log_probs,\\\n",
    "                    log_coeffs, rn_log_probs, final_log_probs=return_list[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "a=pickle.load(open(r'D:\\users\\t-yicxu\\BiMPM_1.0\\model_data\\res_check.pkg','rb'))\n",
    "return_list_check=a\n",
    "_, loss_summary,loss_value, pred, prob, all_probs, correct, gate_prob, gate_log_prob, weighted_log_probs, log_coeffs=\\\n",
    "    return_list_check[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [-0.05338239 -0.03579656 -0.00162901 -0.00174587  0.0242334   0.02117068\n",
      " -0.04450436 -0.01070562 -0.02608017  0.04814645 -0.03842793  0.01441126\n",
      " -0.03165714  0.00683664  0.01342158  0.01780171  0.00117559 -0.0039091\n",
      "  0.01413208 -0.00078521]\n",
      "second: [ 0.35946044  0.1902172   0.55442131  0.23845562  0.4498654   0.61483067\n",
      "  0.47724396  0.01787077  0.2486598  -0.01556147  0.6364758   0.55488175\n",
      "  0.4180097   0.3101069   0.37093768  0.45258409  0.43959406  0.47301584\n",
      "  0.44902706  0.48711446]\n",
      "diff: [-0.41284284 -0.22601375 -0.5560503  -0.24020149 -0.425632   -0.59366\n",
      " -0.5217483  -0.02857639 -0.27473998  0.06370791 -0.67490375 -0.54047048\n",
      " -0.44966686 -0.30327028 -0.35751608 -0.43478239 -0.43841848 -0.47692496\n",
      " -0.43489498 -0.48789966]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (800,) (232000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-402-df7d2563ca8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0midd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'argmax,'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_list_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# print('first:',np.exp(return_list[idx]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# print('second:',np.exp(return_list_check[idx]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-402-df7d2563ca8d>\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(mata, matb)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'second:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'diff:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0midd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'argmax,'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_list_check\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (800,) (232000,) "
     ]
    }
   ],
   "source": [
    "idx=-8\n",
    "def display(mata,matb):\n",
    "    aa=np.reshape(mata,[-1])\n",
    "    bb=np.reshape(matb,[-1])\n",
    "    print('first:',aa[0:20])\n",
    "    print('second:',bb[0:20])\n",
    "    print('diff:',aa[0:20]-bb[0:20])\n",
    "    idd=np.argmax(aa-bb)\n",
    "    print('argmax,',aa[idd],bb[idd],aa[idd]-bb[idd])\n",
    "display(return_list[idx],return_list_check[idx])\n",
    "# print('first:',np.exp(return_list[idx]))\n",
    "# print('second:',np.exp(return_list_check[idx]))\n",
    "aaid=np.argmax(return_list[idx]-return_list_check[idx])\n",
    "print(return_list[idx].shape)\n",
    "print(np.unravel_index(aaid,return_list[idx].shape))\n",
    "print('diff:',np.max(np.exp(return_list[idx])-np.exp(return_list_check[idx])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.02282524 -0.01701759]\n",
      "  [-0.03286276 -0.02164031]\n",
      "  [-0.07693908 -0.05053991]\n",
      "  [-0.05101457 -0.        ]\n",
      "  [-0.038577   -0.        ]\n",
      "  [-0.03918257 -0.02227946]\n",
      "  [-0.03652685 -0.02651657]\n",
      "  [-0.05224882 -0.04035052]\n",
      "  [-0.04863837 -0.        ]\n",
      "  [-0.03742849 -0.01766848]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]]\n",
      "\n",
      " [[-0.01115153 -0.01729579]\n",
      "  [-0.01830848 -0.0126055 ]\n",
      "  [-0.01901939 -0.02244679]\n",
      "  [-0.07131419 -0.        ]\n",
      "  [-0.08853654 -0.05599148]\n",
      "  [-0.06382308 -0.02942242]\n",
      "  [-0.07364358 -0.03909869]\n",
      "  [-0.07605171 -0.04985303]\n",
      "  [-0.08751858 -0.06604198]\n",
      "  [-0.08478907 -0.06961805]\n",
      "  [-0.05645728 -0.04077989]\n",
      "  [-0.05456866 -0.0425219 ]\n",
      "  [-0.01788496 -0.        ]\n",
      "  [-0.         -0.0109001 ]]\n",
      "\n",
      " [[-0.03531496 -0.03036399]\n",
      "  [-0.03296646 -0.        ]\n",
      "  [-0.03556396 -0.02987739]\n",
      "  [-0.0307349  -0.02677712]\n",
      "  [-0.04976944 -0.04578488]\n",
      "  [-0.         -0.04217978]\n",
      "  [-0.04014491 -0.02334485]\n",
      "  [-0.05714534 -0.04322929]\n",
      "  [-0.06738655 -0.03953866]\n",
      "  [-0.05582616 -0.0344174 ]\n",
      "  [-0.0530524  -0.02613096]\n",
      "  [-0.04487427 -0.01722923]\n",
      "  [-0.05716886 -0.01636374]\n",
      "  [-0.06154688 -0.        ]]\n",
      "\n",
      " [[-0.         -0.01459334]\n",
      "  [-0.01867923 -0.00289975]\n",
      "  [-0.03608929 -0.02509199]\n",
      "  [-0.03743106 -0.01881441]\n",
      "  [-0.03313595 -0.02697652]\n",
      "  [-0.07189775 -0.        ]\n",
      "  [-0.06029094 -0.05059123]\n",
      "  [-0.05632369 -0.04044408]\n",
      "  [-0.07306301 -0.05065348]\n",
      "  [-0.07306301 -0.05065348]\n",
      "  [-0.07306301 -0.05065348]\n",
      "  [-0.07306301 -0.05065348]\n",
      "  [-0.07306301 -0.05065348]\n",
      "  [-0.07306301 -0.05065348]]]\n",
      "[[[-0.02282524 -0.01701759]\n",
      "  [-0.03286276 -0.02164031]\n",
      "  [-0.07693908 -0.05053991]\n",
      "  [-0.05101457 -0.0270427 ]\n",
      "  [-0.038577   -0.02384669]\n",
      "  [-0.03918257 -0.02227946]\n",
      "  [-0.         -0.02651657]\n",
      "  [-0.05224882 -0.04035052]\n",
      "  [-0.04863837 -0.03466211]\n",
      "  [-0.03742849 -0.01766848]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]\n",
      "  [-0.05330294 -0.03132046]]\n",
      "\n",
      " [[-0.01115153 -0.01729579]\n",
      "  [-0.01830848 -0.0126055 ]\n",
      "  [-0.         -0.02244679]\n",
      "  [-0.07131419 -0.0533799 ]\n",
      "  [-0.08853654 -0.05599148]\n",
      "  [-0.06382308 -0.02942242]\n",
      "  [-0.07364358 -0.03909869]\n",
      "  [-0.07605171 -0.04985303]\n",
      "  [-0.08751858 -0.06604198]\n",
      "  [-0.08478907 -0.06961805]\n",
      "  [-0.05645728 -0.04077989]\n",
      "  [-0.05456866 -0.0425219 ]\n",
      "  [-0.         -0.        ]\n",
      "  [-0.03413916 -0.0109001 ]]\n",
      "\n",
      " [[-0.03531496 -0.03036399]\n",
      "  [-0.03296646 -0.03547446]\n",
      "  [-0.03556396 -0.02987739]\n",
      "  [-0.         -0.02677712]\n",
      "  [-0.04976944 -0.04578488]\n",
      "  [-0.0490558  -0.04217978]\n",
      "  [-0.04014491 -0.02334485]\n",
      "  [-0.05714534 -0.04322929]\n",
      "  [-0.         -0.03953866]\n",
      "  [-0.05582616 -0.0344174 ]\n",
      "  [-0.0530524  -0.02613096]\n",
      "  [-0.04487427 -0.01722923]\n",
      "  [-0.05716886 -0.01636374]\n",
      "  [-0.06154688 -0.02708839]]\n",
      "\n",
      " [[-0.01991998 -0.01459334]\n",
      "  [-0.01867923 -0.00289975]\n",
      "  [-0.03608929 -0.02509199]\n",
      "  [-0.03743106 -0.01881441]\n",
      "  [-0.03313595 -0.02697652]\n",
      "  [-0.07189775 -0.0488987 ]\n",
      "  [-0.06029094 -0.05059123]\n",
      "  [-0.05632369 -0.04044408]\n",
      "  [-0.07306301 -0.        ]\n",
      "  [-0.07306301 -0.        ]\n",
      "  [-0.07306301 -0.        ]\n",
      "  [-0.07306301 -0.        ]\n",
      "  [-0.07306301 -0.        ]\n",
      "  [-0.07306301 -0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(return_list[16][:,:,0:2])\n",
    "print(return_list_check[16][:,:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24982658  0.2500318   0.2501086   0.25003305]\n",
      " [ 0.24999437  0.24998546  0.25000054  0.25001973]\n",
      " [ 0.24996126  0.25010446  0.24995172  0.2499826 ]\n",
      " [ 0.24962606  0.25019497  0.24989152  0.2502875 ]\n",
      " [ 0.24995506  0.25002325  0.25000477  0.25001699]\n",
      " [ 0.24999678  0.24999493  0.24998081  0.25002754]\n",
      " [ 0.25012159  0.2499589   0.24993965  0.24997982]\n",
      " [ 0.24989535  0.25017554  0.25004786  0.24988124]]\n",
      "[[ 0.24989131  0.24995163  0.25021935  0.24993768]\n",
      " [ 0.249993    0.2499916   0.2500076   0.25000784]\n",
      " [ 0.24997199  0.25013804  0.24988231  0.25000772]\n",
      " [ 0.24961618  0.25018841  0.24996117  0.25023431]\n",
      " [ 0.24995303  0.2500169   0.25001812  0.25001198]\n",
      " [ 0.25002229  0.24999142  0.24997321  0.25001314]\n",
      " [ 0.2501775   0.24994606  0.2499335   0.24994296]\n",
      " [ 0.2498787   0.25013727  0.25006896  0.24991508]]\n",
      "[[ 0.25012746  0.24991067  0.2498869   0.25007498]\n",
      " [ 0.2500124   0.25001019  0.25000501  0.24997237]\n",
      " [ 0.24991517  0.2502045   0.24996075  0.24991952]\n",
      " [ 0.24952358  0.25028268  0.24991609  0.25027752]\n",
      " [ 0.25001532  0.25002056  0.2499727   0.24999145]\n",
      " [ 0.24995688  0.24996191  0.25006711  0.25001407]\n",
      " [ 0.2504954   0.24983878  0.24983117  0.2498346 ]\n",
      " [ 0.24999398  0.25023597  0.24987543  0.24989463]]\n",
      "[[ -6.47306442e-05   8.01682472e-05  -1.10745430e-04   9.53674316e-05]\n",
      " [  1.37090683e-06  -6.13927841e-06  -7.06315041e-06   1.18911266e-05]\n",
      " [ -1.07288361e-05  -3.35872173e-05   6.94096088e-05  -2.51233578e-05]\n",
      " [  9.87946987e-06   6.55651093e-06  -6.96480274e-05   5.31971455e-05]\n",
      " [  2.02655792e-06   6.34789467e-06  -1.33514404e-05   5.00679016e-06]\n",
      " [ -2.55107880e-05   3.51667404e-06   7.59959221e-06   1.43945217e-05]\n",
      " [ -5.59091568e-05   1.28448009e-05   6.15417957e-06   3.68654728e-05]\n",
      " [  1.66445971e-05   3.82661819e-05  -2.11000443e-05  -3.38405371e-05]]\n"
     ]
    }
   ],
   "source": [
    "m1=return_list[-3]\n",
    "m2=return_list[-2]\n",
    "m3=return_list[-1]\n",
    "\n",
    "print(np.exp(m1))\n",
    "print(np.exp(m2))\n",
    "print(np.exp(m3))\n",
    "print(np.exp(all_probs[0,:,:])-np.exp(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  7.18353898e-04   2.79672304e-03   1.25866244e-03   5.25963085e-04]\n",
      "  [  2.75194179e-05   1.34476286e-03   4.49777406e-04   1.38689519e-03]\n",
      "  [  7.06994324e-04   2.73944950e-03   8.53697828e-04   5.23571449e-04]\n",
      "  [ -1.78905204e-04   1.24197651e-03   4.33197012e-04   8.89413757e-04]\n",
      "  [  7.57426023e-04   2.75521306e-03   8.56292958e-04   5.50798548e-04]\n",
      "  [ -1.06962631e-04   1.54142454e-03   4.26312559e-04   1.03132357e-03]\n",
      "  [  7.50457868e-04   2.48117652e-03   9.58303455e-04   5.46024181e-04]\n",
      "  [ -1.65181933e-04   1.33849494e-03   4.04751801e-04   1.04542822e-03]]\n",
      "\n",
      " [[  4.40731086e-03   4.38403105e-03   4.60868422e-03   3.77825508e-03]\n",
      "  [  3.56850494e-03   4.10625804e-03   3.49397981e-03   4.40380163e-03]\n",
      "  [  4.38481802e-03   4.15251637e-03   4.22066171e-03   3.78804049e-03]\n",
      "  [  3.56757734e-03   4.13341075e-03   3.48551152e-03   4.26598871e-03]\n",
      "  [  4.40486660e-03   4.29896358e-03   4.12879698e-03   3.79992742e-03]\n",
      "  [  3.61111993e-03   4.18476854e-03   3.48436367e-03   4.24353871e-03]\n",
      "  [  4.42264136e-03   4.15702770e-03   4.18387400e-03   3.78940254e-03]\n",
      "  [  3.54583492e-03   4.20764601e-03   3.47582088e-03   4.24499204e-03]]\n",
      "\n",
      " [[ -1.70428604e-02  -1.87984705e-02  -1.63938906e-02  -1.78717580e-02]\n",
      "  [ -1.74624380e-02  -1.83163192e-02  -1.50333699e-02  -1.62326973e-02]\n",
      "  [ -1.69133004e-02  -1.19281691e-02  -1.74104143e-02  -1.79230403e-02]\n",
      "  [ -1.72747448e-02  -1.84585564e-02  -1.50046209e-02  -1.63556989e-02]\n",
      "  [ -1.73386764e-02  -1.92082301e-02  -1.74925998e-02  -1.78415217e-02]\n",
      "  [ -1.72379650e-02  -1.82627626e-02  -1.50706088e-02  -1.62944403e-02]\n",
      "  [ -1.71181969e-02  -1.19070029e-02  -1.74224004e-02  -1.78959072e-02]\n",
      "  [ -1.74285397e-02  -1.82211921e-02  -1.50390510e-02  -1.62952542e-02]]]\n",
      "[[  7.18353898e-04   2.79672304e-03   1.25866244e-03   5.25963085e-04]\n",
      " [  2.75194179e-05   1.34476286e-03   4.49777406e-04   1.38689519e-03]\n",
      " [  7.06994324e-04   2.73944950e-03   8.53697828e-04   5.23571449e-04]\n",
      " [ -1.78905204e-04   1.24197651e-03   4.33197012e-04   8.89413757e-04]\n",
      " [  7.57426023e-04   2.75521306e-03   8.56292958e-04   5.50798548e-04]\n",
      " [ -1.06962631e-04   1.54142454e-03   4.26312559e-04   1.03132357e-03]\n",
      " [  7.50457868e-04   2.48117652e-03   9.58303455e-04   5.46024181e-04]\n",
      " [ -1.65181933e-04   1.33849494e-03   4.04751801e-04   1.04542822e-03]]\n",
      "[[ 0.00440731  0.00438403  0.00460868  0.00377826]\n",
      " [ 0.0035685   0.00410626  0.00349398  0.0044038 ]\n",
      " [ 0.00438482  0.00415252  0.00422066  0.00378804]\n",
      " [ 0.00356758  0.00413341  0.00348551  0.00426599]\n",
      " [ 0.00440487  0.00429896  0.0041288   0.00379993]\n",
      " [ 0.00361112  0.00418477  0.00348436  0.00424354]\n",
      " [ 0.00442264  0.00415703  0.00418387  0.0037894 ]\n",
      " [ 0.00354583  0.00420765  0.00347582  0.00424499]]\n",
      "[[-0.01704286 -0.01879847 -0.01639389 -0.01787176]\n",
      " [-0.01746244 -0.01831632 -0.01503337 -0.0162327 ]\n",
      " [-0.0169133  -0.01192817 -0.01741041 -0.01792304]\n",
      " [-0.01727474 -0.01845856 -0.01500462 -0.0163557 ]\n",
      " [-0.01733868 -0.01920823 -0.0174926  -0.01784152]\n",
      " [-0.01723797 -0.01826276 -0.01507061 -0.01629444]\n",
      " [-0.0171182  -0.011907   -0.0174224  -0.01789591]\n",
      " [-0.01742854 -0.01822119 -0.01503905 -0.01629525]]\n"
     ]
    }
   ],
   "source": [
    "mm=return_list[-4]\n",
    "m1=return_list[-3]\n",
    "m2=return_list[-2]\n",
    "m3=return_list[-1]\n",
    "\n",
    "print(np.reshape(mm[:,5],[3,8,4]))\n",
    "print(np.reshape(m1[:,5],[8,4]))\n",
    "print(np.reshape(m2[:,5],[8,4]))\n",
    "print(np.reshape(m3[:,5],[8,4]))\n",
    "\n",
    "\n",
    "# print(np.exp(m1))\n",
    "# print(np.exp(m2))\n",
    "# print(np.exp(m3))\n",
    "# print(np.exp(all_probs[0,:,:])-np.exp(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.08362758  0.08359282  0.08360495  0.08361283]\n",
      "  [ 0.08355609  0.08358564  0.08356237  0.08356472]\n",
      "  [ 0.08359728  0.08358181  0.08358293  0.08359039]\n",
      "  [ 0.08356803  0.08358389  0.08356271  0.08359792]\n",
      "  [ 0.08353203  0.08353364  0.08354775  0.08354912]\n",
      "  [ 0.08364023  0.08363608  0.08366244  0.08364896]\n",
      "  [ 0.08351967  0.08352293  0.08351202  0.08353098]\n",
      "  [ 0.08357743  0.08358169  0.08357377  0.08356414]]\n",
      "\n",
      " [[ 0.08347926  0.08345215  0.0834545   0.08346909]\n",
      "  [ 0.08345458  0.0834276   0.08346123  0.08344534]\n",
      "  [ 0.08343583  0.08343906  0.08344286  0.08344872]\n",
      "  [ 0.08353759  0.08352432  0.0835255   0.08353873]\n",
      "  [ 0.08348065  0.08346504  0.08346606  0.0834547 ]\n",
      "  [ 0.08349466  0.08350489  0.08348395  0.08350248]\n",
      "  [ 0.08349233  0.083473    0.08347473  0.08348478]\n",
      "  [ 0.08351166  0.08350899  0.08350513  0.08350205]]\n",
      "\n",
      " [[ 0.082909    0.08294848  0.08292663  0.08292264]\n",
      "  [ 0.0829995   0.08300991  0.08296516  0.08296791]\n",
      "  [ 0.08296441  0.08297049  0.08297861  0.08296768]\n",
      "  [ 0.08290437  0.08289259  0.08288077  0.0828837 ]\n",
      "  [ 0.08299432  0.08300811  0.0829773   0.08299129]\n",
      "  [ 0.08285576  0.08287406  0.08284265  0.08285382]\n",
      "  [ 0.08301193  0.08299588  0.08299946  0.08298229]\n",
      "  [ 0.08292402  0.0829298   0.08291157  0.08290975]]]\n"
     ]
    }
   ],
   "source": [
    "weighted_probs=np.exp(weighted_log_probs)\n",
    "print(weighted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[[ 0.3344382   0.33426884  0.3343524   0.33431256  0.33416253  0.33458769\n",
      "   0.33408558  0.33429706]\n",
      " [ 0.333855    0.33378869  0.33376646  0.33412614  0.33386645  0.33398595\n",
      "   0.33392486  0.33402786]\n",
      " [ 0.33170673  0.33194247  0.3318812   0.33156139  0.33197102  0.33142629\n",
      "   0.33198953  0.33167514]]\n",
      "[[ 0.3344382   0.333855    0.33170673]\n",
      " [ 0.33426887  0.33378872  0.3319425 ]\n",
      " [ 0.33435243  0.33376646  0.3318812 ]\n",
      " [ 0.33431256  0.33412611  0.33156139]\n",
      " [ 0.33416253  0.33386645  0.33197102]\n",
      " [ 0.33458772  0.33398598  0.33142629]\n",
      " [ 0.33408558  0.33392486  0.33198953]\n",
      " [ 0.33429703  0.33402783  0.33167511]]\n"
     ]
    }
   ],
   "source": [
    "rn_probs=np.exp(rn_log_probs)\n",
    "print(rn_probs)\n",
    "print(np.sum(rn_probs[1::3,:],axis=0))\n",
    "final_prob=np.exp(final_log_probs)\n",
    "print(final_prob)\n",
    "print(gate_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.25005394  0.24994996  0.24998626  0.2500098 ]\n",
      "  [ 0.24996674  0.25005516  0.24998549  0.24999255]\n",
      "  [ 0.25002748  0.24998122  0.24998453  0.25000679]\n",
      "  [ 0.24996978  0.25001723  0.24995384  0.25005919]\n",
      "  [ 0.24997425  0.24997911  0.25002125  0.25002539]\n",
      "  [ 0.24998     0.24996758  0.25004634  0.25000608]\n",
      "  [ 0.24999484  0.25000459  0.2499719   0.25002867]\n",
      "  [ 0.25000951  0.25002226  0.24999851  0.24996972]]\n",
      "\n",
      " [[ 0.25004646  0.24996525  0.24997228  0.25001597]\n",
      "  [ 0.25002217  0.24994135  0.25004208  0.24999449]\n",
      "  [ 0.24998271  0.24999234  0.25000373  0.25002128]\n",
      "  [ 0.25001812  0.24997845  0.24998194  0.25002152]\n",
      "  [ 0.25004205  0.24999529  0.24999833  0.2499643 ]\n",
      "  [ 0.24999455  0.25002515  0.24996242  0.25001794]\n",
      "  [ 0.25003329  0.24997544  0.2499806   0.2500107 ]\n",
      "  [ 0.25001407  0.25000605  0.24999455  0.24998528]]\n",
      "\n",
      " [[ 0.24994668  0.25006571  0.24999982  0.24998778]\n",
      "  [ 0.25004178  0.25007319  0.24993831  0.24994662]\n",
      "  [ 0.24998227  0.25000057  0.25002503  0.24999216]\n",
      "  [ 0.25004229  0.25000677  0.24997109  0.24997991]\n",
      "  [ 0.25000471  0.25004625  0.24995345  0.24999559]\n",
      "  [ 0.24999753  0.25005275  0.24995795  0.24999171]\n",
      "  [ 0.25004381  0.24999547  0.25000626  0.24995449]\n",
      "  [ 0.25001583  0.25003323  0.24997824  0.24997273]]]\n",
      "[[ 0.25001583  0.24999344  0.24998608  0.25000456]\n",
      " [ 0.25001016  0.25002316  0.24998876  0.24997798]\n",
      " [ 0.24999751  0.24999136  0.25000441  0.25000679]\n",
      " [ 0.25000998  0.2500008   0.24996898  0.25002033]\n",
      " [ 0.250007    0.25000679  0.24999112  0.2499951 ]\n",
      " [ 0.24999064  0.25001502  0.24998903  0.25000525]\n",
      " [ 0.25002393  0.24999182  0.2499862   0.24999805]\n",
      " [ 0.25001311  0.25002047  0.24999046  0.24997593]]\n",
      "[[ 0.25001583  0.24999344  0.24998608  0.25000453]\n",
      " [ 0.25001016  0.25002316  0.24998876  0.24997796]\n",
      " [ 0.2499975   0.24999136  0.25000441  0.25000679]\n",
      " [ 0.25000998  0.2500008   0.24996898  0.25002033]\n",
      " [ 0.25000697  0.25000679  0.24999109  0.2499951 ]\n",
      " [ 0.24999064  0.25001502  0.24998903  0.25000525]\n",
      " [ 0.2500239   0.24999182  0.2499862   0.24999803]\n",
      " [ 0.25001311  0.25002047  0.24999046  0.24997593]]\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(all_probs))\n",
    "print(np.sum(weighted_probs,axis=0))\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(return_list[18]-return_list_check[19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 (15, 4)\n",
      "12 (15, 4)\n",
      "13 (16, 14, 12)\n",
      "14 (16, 13, 12)\n",
      "15 (16, 27, 12)\n",
      "16 (4, 14, 100)\n",
      "17 (4, 14, 100)\n",
      "18 (16, 13, 100)\n",
      "19 (16, 13, 100)\n",
      "20 (16, 27, 100)\n",
      "21 (16, 27, 100)\n",
      "22 (16, 27, 116)\n",
      "23 (16, 14, 212)\n",
      "24 (16, 13, 116)\n",
      "25 (16, 14, 116)\n",
      "26 (16, 13, 116)\n",
      "27 (4, 500, 116)\n",
      "28 (240, 400)\n",
      "29 (16, 400)\n",
      "30 (16, 400)\n",
      "31 (16, 400)\n",
      "32 (4, 4)\n",
      "33 (4, 4)\n",
      "34 (4, 4)\n"
     ]
    }
   ],
   "source": [
    "for i,tensor in enumerate(return_list_check[11:]):\n",
    "    print(11+i,tensor.shape)\n",
    "    \n",
    "# print(return_list[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 3, 4)\n",
      "1 (15, 4)\n",
      "2 (16, 14, 12)\n",
      "3 (16, 13, 12)\n",
      "4 (16, 27, 12)\n",
      "5 (4, 14, 100)\n",
      "6 (4, 14, 100)\n",
      "7 (16, 13, 100)\n",
      "8 (16, 13, 100)\n",
      "9 (16, 27, 100)\n",
      "10 (16, 27, 100)\n",
      "11 (16, 27, 116)\n",
      "12 (16, 14, 212)\n",
      "13 (16, 13, 116)\n",
      "14 (16, 14, 116)\n",
      "15 (16, 13, 116)\n",
      "16 (4, 500, 116)\n",
      "17 (4, 200)\n",
      "18 (240, 400)\n",
      "19 (16, 400)\n",
      "20 (16, 400)\n",
      "21 (16, 400)\n",
      "22 (4, 4)\n",
      "23 (4, 4)\n",
      "24 (4, 4)\n"
     ]
    }
   ],
   "source": [
    "for i,tensor in enumerate(return_list[11:]):\n",
    "    print(i,tensor.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.937779769301\n",
      "-0.93778\n"
     ]
    }
   ],
   "source": [
    "mapped_memory=return_list[27]\n",
    "mapped_state=return_list[28]\n",
    "relevancy_mat=return_list[29]\n",
    "\n",
    "a=mapped_memory[5,28,:]\n",
    "b=mapped_state[5]\n",
    "\n",
    "res=np.sum(a*b)/np.linalg.norm(a)/np.linalg.norm(b)*10\n",
    "print(res)\n",
    "print(relevancy_mat[5,28])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.62487548e-05   4.44342091e-04]\n",
      " [ -7.64372380e-05   4.37776267e-04]\n",
      " [ -3.90062451e-05   3.03555455e-04]\n",
      " [ -8.24017334e-05   4.42831835e-04]\n",
      " [ -6.33206000e-05   3.22173553e-04]\n",
      " [ -4.64778386e-05   4.71606123e-04]\n",
      " [ -7.84207368e-05   4.42743330e-04]\n",
      " [ -4.94958949e-05   4.75252658e-04]]\n",
      "[[ 0.00152851 -0.00105755]\n",
      " [ 0.00151069 -0.0007429 ]]\n",
      "[-0.0017655   0.00257037]\n",
      "[-0.0017655   0.00257037]\n"
     ]
    }
   ],
   "source": [
    "first_logit=return_list[32]\n",
    "second_logit=return_list[33]\n",
    "\n",
    "print(first_logit)\n",
    "print(second_logit)\n",
    "print(np.sum(first_logit[::2,:],axis=0)-second_logit[0,:])\n",
    "print(np.sum(first_logit[1::2,:],axis=0)-second_logit[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 22, 116)\n",
      "[[ 0.96780843  0.96449792  0.96625811  0.96739197  0.9685812   0.97571802\n",
      "   0.97127086]\n",
      " [ 0.9645583   0.9646889   0.97126222  0.9648385   0.96542144  0.97792894\n",
      "   0.97705621]\n",
      " [ 0.98416954  0.98316449  0.98878545  0.98518354  0.98554319  0.98773217\n",
      "   0.98972249]\n",
      " [ 0.94720751  0.94928014  0.95599389  0.94866806  0.94901693  0.97112852\n",
      "   0.97025681]\n",
      " [ 0.96582401  0.96524531  0.97039443  0.96466416  0.96813524  0.9755702\n",
      "   0.97572088]\n",
      " [ 0.99202555  0.99069554  0.99341303  0.99252582  0.99336565  0.98939389\n",
      "   0.99066943]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "att_mat=return_list[-3]\n",
    "print(att_mat.shape)\n",
    "# print(np.mean(att_mat[1,:,0:1],axis=1))\n",
    "print(att_mat[0,:,-10:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 278, 116)\n",
      "[ 0.70617902  0.89402467  0.13805355  0.18364534  0.18686165  0.17681293\n",
      "  0.15464354  0.16170824  0.15627143  0.07479369  0.19147879  0.15051953\n",
      "  0.17610396  0.14992096  0.22704741  0.20931911  0.08613152  0.1677404\n",
      "  0.20090869  0.15794253  0.15761678  0.03717952  0.05461993  0.\n",
      "  0.15326682  0.19534087  0.14648175  0.01139965  0.162386    0.03711824\n",
      "  0.09814952  0.16980778  0.13124457  0.20247559  0.16435823  0.15736075\n",
      "  0.16621098  0.04268411  0.16859578  0.16825555  0.          0.19273819\n",
      "  0.15233463  0.13316262  0.16191345  0.2734704   0.17385669  0.16149832\n",
      "  0.16512822  0.15580325  0.24795924  0.16937433  0.1674049   0.10692158\n",
      "  0.16819863  0.21359205  0.16403605  0.10429514  0.13125519  0.15053403\n",
      "  0.15640496  0.16045077  0.          0.21689132  0.17126852  0.15449862\n",
      "  0.11651728  0.16125877  0.          0.21678223  0.18384522  0.18571852\n",
      "  0.09927992  0.16825266  0.19165443  0.20525195  0.18343164  0.00954874]\n",
      "[ 0.23760802  0.04303952  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "att_mat=return_list[-1]\n",
    "print(att_mat.shape)\n",
    "print(np.mean(att_mat[0,200:,3:4],axis=1))\n",
    "print(att_mat[0,200:,-14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33389902,  0.33328748,  0.33281353],\n",
       "       [ 0.3337996 ,  0.33331674,  0.33288369]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(gate_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_probs=np.exp(weighted_log_probs)\n",
    "weighted_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63360476,  0.6337207 ,  0.63391227,  0.63396388],\n",
       "       [ 0.63366437,  0.63367271,  0.63373494,  0.63381332]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63360476,  0.6337207 ,  0.63391227,  0.63396388],\n",
       "       [ 0.63366437,  0.63367271,  0.63373494,  0.63381332]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(weighted_probs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.38685298, -1.38659048, -1.38573396, -1.38600063],\n",
       "        [-1.38614523, -1.38617289, -1.3865056 , -1.38635361]],\n",
       "\n",
       "       [[-1.38637722, -1.38691151, -1.38615716, -1.38573194],\n",
       "        [-1.38640547, -1.38649654, -1.38627064, -1.38600528]],\n",
       "\n",
       "       [[-1.38633752, -1.38676381, -1.38663411, -1.38544226],\n",
       "        [-1.38642931, -1.38652742, -1.38630176, -1.38591897]],\n",
       "\n",
       "       [[-1.38656819, -1.38679373, -1.38606763, -1.38574815],\n",
       "        [-1.38619244, -1.38627231, -1.38660908, -1.38610363]],\n",
       "\n",
       "       [[-1.38638389, -1.38644862, -1.38627124, -1.38607395],\n",
       "        [-1.38615954, -1.38625622, -1.38646817, -1.38629329]],\n",
       "\n",
       "       [[-1.38661265, -1.38612878, -1.38643062, -1.38600552],\n",
       "        [-1.38623416, -1.38628328, -1.38633084, -1.38632929]],\n",
       "\n",
       "       [[-1.38618493, -1.38657069, -1.38669467, -1.38572776],\n",
       "        [-1.3865751 , -1.3862325 , -1.38620842, -1.38616109]],\n",
       "\n",
       "       [[-1.3865999 , -1.38674128, -1.38569212, -1.38614416],\n",
       "        [-1.38672328, -1.38631153, -1.38634467, -1.3857981 ]],\n",
       "\n",
       "       [[-1.38685262, -1.38658249, -1.38588428, -1.3858583 ],\n",
       "        [-1.38605511, -1.3868494 , -1.38618398, -1.38608944]],\n",
       "\n",
       "       [[-1.38677084, -1.38629472, -1.38593435, -1.3861779 ],\n",
       "        [-1.38667369, -1.38619864, -1.38619733, -1.38610768]],\n",
       "\n",
       "       [[-1.38652599, -1.38650727, -1.38583016, -1.38631403],\n",
       "        [-1.38625252, -1.38618445, -1.38629425, -1.38644612]],\n",
       "\n",
       "       [[-1.38676214, -1.38629472, -1.38622725, -1.38589334],\n",
       "        [-1.38638508, -1.38618183, -1.38614297, -1.38646746]],\n",
       "\n",
       "       [[-1.38661373, -1.38661397, -1.38606691, -1.38588274],\n",
       "        [-1.38653135, -1.38646722, -1.38626158, -1.38591754]],\n",
       "\n",
       "       [[-1.38669991, -1.38583922, -1.38633311, -1.38630533],\n",
       "        [-1.38617516, -1.38656712, -1.38602185, -1.38641346]],\n",
       "\n",
       "       [[-1.38685703, -1.38525581, -1.38596332, -1.38710201],\n",
       "        [-1.3864665 , -1.38608515, -1.38630652, -1.38631964]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49812546  0.4981159 ]\n",
      " [ 0.49822628  0.49821955]\n",
      " [ 0.49807879  0.49811491]\n",
      " [ 0.24990763  0.2498958 ]\n",
      " [ 0.24984105  0.24971937]\n",
      " [ 0.25004572  0.24991085]\n",
      " [ 0.12544356  0.12545627]\n",
      " [ 0.12539801  0.12540391]\n",
      " [ 0.12528025  0.12535958]\n",
      " [ 0.06283034  0.0628693 ]\n",
      " [ 0.06282656  0.06290468]\n",
      " [ 0.06296083  0.06292958]\n",
      " [ 0.06369305  0.06366275]\n",
      " [ 0.06370806  0.06375255]\n",
      " [ 0.06363437  0.06368511]]\n",
      "[[ 0.16541335  0.16554733]\n",
      " [ 0.16736852  0.16744888]\n",
      " [ 0.16536197  0.16515425]\n",
      " [ 0.08298723  0.08305211]\n",
      " [ 0.08392879  0.08392932]\n",
      " [ 0.0830151   0.08286007]\n",
      " [ 0.04165626  0.04169501]\n",
      " [ 0.04212479  0.04214757]\n",
      " [ 0.041593    0.04156403]\n",
      " [ 0.02086417  0.02089442]\n",
      " [ 0.02110524  0.02114192]\n",
      " [ 0.02090297  0.02086484]\n",
      " [ 0.02115066  0.02115812]\n",
      " [ 0.02140137  0.02142688]\n",
      " [ 0.02112659  0.02111534]]\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(rn_log_probs))\n",
    "print(np.exp(final_log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99999994,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(rn_log_probs[2::3]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.25003216,  0.25004417,  0.24989669,  0.25002691],\n",
       "        [ 0.24998498,  0.24992149,  0.25005293,  0.25004065]],\n",
       "\n",
       "       [[ 0.25002819,  0.25005001,  0.25000742,  0.24991439],\n",
       "        [ 0.25005233,  0.24998406,  0.24998909,  0.24997452]],\n",
       "\n",
       "       [[ 0.24998736,  0.25002605,  0.25000602,  0.2499806 ],\n",
       "        [ 0.24991651,  0.24999455,  0.25004551,  0.25004351]],\n",
       "\n",
       "       [[ 0.25001457,  0.25001135,  0.25008005,  0.24989398],\n",
       "        [ 0.25002536,  0.25001439,  0.249951  ,  0.25000921]],\n",
       "\n",
       "       [[ 0.25004506,  0.25005576,  0.25008625,  0.24981283],\n",
       "        [ 0.24990402,  0.25007662,  0.25008306,  0.24993628]],\n",
       "\n",
       "       [[ 0.24998933,  0.25008044,  0.24993061,  0.24999967],\n",
       "        [ 0.2500242 ,  0.25006312,  0.25001851,  0.24989413]],\n",
       "\n",
       "       [[ 0.25001284,  0.24996424,  0.25007904,  0.24994388],\n",
       "        [ 0.24997827,  0.25016367,  0.25001252,  0.24984558]],\n",
       "\n",
       "       [[ 0.25003099,  0.25000334,  0.25001991,  0.24994573],\n",
       "        [ 0.25011516,  0.2500394 ,  0.24991544,  0.24993007]],\n",
       "\n",
       "       [[ 0.25000703,  0.25012392,  0.24995193,  0.24991708],\n",
       "        [ 0.24998626,  0.25015593,  0.24997193,  0.24988598]],\n",
       "\n",
       "       [[ 0.25006774,  0.2499629 ,  0.25004646,  0.24992286],\n",
       "        [ 0.25007588,  0.24993183,  0.25001201,  0.24998021]],\n",
       "\n",
       "       [[ 0.25009128,  0.24988884,  0.25004962,  0.24997035],\n",
       "        [ 0.25000447,  0.25010255,  0.24990226,  0.2499907 ]],\n",
       "\n",
       "       [[ 0.24998423,  0.25004807,  0.24999946,  0.24996823],\n",
       "        [ 0.25006789,  0.2499335 ,  0.25007126,  0.24992733]],\n",
       "\n",
       "       [[ 0.2499887 ,  0.24994731,  0.25004819,  0.2500158 ],\n",
       "        [ 0.25008065,  0.2499014 ,  0.25008857,  0.24992944]],\n",
       "\n",
       "       [[ 0.25001594,  0.24991073,  0.25004101,  0.25003228],\n",
       "        [ 0.24997067,  0.25012517,  0.24997425,  0.24992989]],\n",
       "\n",
       "       [[ 0.25003049,  0.24995741,  0.2500177 ,  0.24999443],\n",
       "        [ 0.25013036,  0.24996868,  0.24989425,  0.25000665]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp=np.tile(gate_prob.transpose(),(1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.33365992],\n",
       "        [ 0.3339709 ]],\n",
       "\n",
       "       [[ 0.33400437],\n",
       "        [ 0.33372563]],\n",
       "\n",
       "       [[ 0.33233574],\n",
       "        [ 0.33230346]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp=np.expand_dims(gate_prob.transpose(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=np.tile(tmp,(1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.33365992,  0.33365992,  0.33365992,  0.33365992],\n",
       "        [ 0.3339709 ,  0.3339709 ,  0.3339709 ,  0.3339709 ]],\n",
       "\n",
       "       [[ 0.33400437,  0.33400437,  0.33400437,  0.33400437],\n",
       "        [ 0.33372563,  0.33372563,  0.33372563,  0.33372563]],\n",
       "\n",
       "       [[ 0.33233574,  0.33233574,  0.33233574,  0.33233574],\n",
       "        [ 0.33230346,  0.33230346,  0.33230346,  0.33230346]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24997705,  0.25000286,  0.25001791,  0.25000221],\n",
       "       [ 0.25000575,  0.25002018,  0.25001246,  0.24996166]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp*all_probs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24997705,  0.25000286,  0.25001791,  0.25000221],\n",
       "       [ 0.25000575,  0.25002018,  0.25001246,  0.24996166]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24997705,  0.25000286,  0.25001788,  0.25000218],\n",
       "       [ 0.25000575,  0.25002018,  0.25001246,  0.24996167]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_probs=np.exp(weighted_log_probs)\n",
    "weighted_probs.shape\n",
    "np.sum(weighted_probs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4328276729559748\n"
     ]
    }
   ],
   "source": [
    "num_all=19736\n",
    "num_middle=5744\n",
    "num_high=num_all-num_middle\n",
    "\n",
    "correct_all=45.36/100\n",
    "correct_middle=50.42/100\n",
    "\n",
    "correct_high=(num_all*correct_all-correct_middle*num_middle)/num_high\n",
    "print(correct_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4371286449399657\n"
     ]
    }
   ],
   "source": [
    "num_all=19736\n",
    "num_middle=5744\n",
    "num_high=num_all-num_middle\n",
    "\n",
    "correct_all=45.24/100\n",
    "correct_middle=48.96/100\n",
    "\n",
    "correct_high=(num_all*correct_all-correct_middle*num_middle)/num_high\n",
    "print(correct_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Placeholder:0' shape=(?, 5) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a=tf.placeholder(tf.float32, [None, 5])\n",
    "print(a.get_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(a.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "a=[0,1,2]\n",
    "if a:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
